{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c79141-9bff-4d73-a9ff-fe411663fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import pyreax\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    # relative import; better to pip install subctrl\n",
    "    import sys\n",
    "    sys.path.append(\"..\")\n",
    "    import pyreax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cfd8e8-e413-437a-90d5-7ce68560b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/wuzhengx/ipykernel_111067/408558312.py:18: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, pyreft\n",
    "from pyvene import (\n",
    "    IntervenableModel,\n",
    "    ConstantSourceIntervention,\n",
    "    SourcelessIntervention,\n",
    "    TrainableIntervention,\n",
    "    DistributedRepresentationIntervention,\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from circuitsvis.tokens import colored_tokens\n",
    "from IPython.core.display import display, HTML\n",
    "from pyreax import (\n",
    "    EXAMPLE_TAG, \n",
    "    ReAXFactory, \n",
    "    MaxReLUIntervention, \n",
    "    SubspaceAdditionIntervention, \n",
    "    JumpReLUSAECollectIntervention,\n",
    "    make_data_module, \n",
    "    save_reax,\n",
    "    load_reax,\n",
    "    load_sae,\n",
    ")\n",
    "from pyreax import (\n",
    "    set_decoder_norm_to_unit_norm, \n",
    "    remove_gradient_parallel_to_decoder_directions,\n",
    "    gather_residual_activations,\n",
    "    get_lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb46e64e-b7ae-44dd-9c6a-10cde9ee47b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4633e96c48d041c29ce713180936b95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01f03f67c514d7abdefab337e5258da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load lm.\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cpu\")\n",
    "model.config.use_cache = False\n",
    "model = model.cuda()\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da7aa466-a829-4b75-8081-1656fc3d2f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df, concept_metadata, weights = load_reax(\"./tmp_save/\")\n",
    "sae_weights = load_sae(concept_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc6681d-014f-469f-8f00-122709c95fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = 20\n",
    "\n",
    "reax_intervention = MaxReLUIntervention(\n",
    "    embed_dim=model.config.hidden_size, low_rank_dimension=weights.shape[0],\n",
    ")\n",
    "reax_intervention.proj.weight.data = weights.data\n",
    "_ = reax_intervention.cuda()\n",
    "pv_reax_model = IntervenableModel({\n",
    "   \"component\": f\"model.layers[{LAYER}].output\",\n",
    "   \"intervention\": reax_intervention}, model=model)\n",
    "\n",
    "sae_intervention = JumpReLUSAECollectIntervention(\n",
    "    embed_dim=sae_weights['W_enc'].shape[0],\n",
    "    low_rank_dimension=sae_weights['W_enc'].shape[1]\n",
    ")\n",
    "sae_intervention.load_state_dict(sae_weights, strict=False)\n",
    "_ = sae_intervention.cuda()\n",
    "pv_sae_model = IntervenableModel({\n",
    "   \"component\": f\"model.layers[{LAYER}].output\",\n",
    "   \"intervention\": sae_intervention}, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a98ef75-9d60-4eca-8f19-d4193e9a635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Less than 2 concepts are provided. Only eval mode is allowed.\n",
      "Prepare contrast concepts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with concept: terms related to artificiality and deception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fectching 2 contrast concepts for concept: terms related to artificiality and deception\n",
      "Creating dataframe.\n",
      "Creating dataframe.\n",
      "Creating dataframe.\n",
      "Less than 2 concepts are provided. Only eval mode is allowed.\n",
      "Prepare contrast concepts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with concept: terms related to employment and employees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fectching 0 contrast concepts for concept: terms related to employment and employees\n",
      "Creating dataframe.\n",
      "Creating dataframe.\n",
      "Creating dataframe.\n"
     ]
    }
   ],
   "source": [
    "dump_dir = \"./tmp\"\n",
    "val_n = 10\n",
    "n_decimal = 3\n",
    "reax_topk = 10\n",
    "\n",
    "all_validation_dfs = []\n",
    "\n",
    "for meta in concept_metadata:\n",
    "    \n",
    "    meta_dict = json.loads(meta)\n",
    "    concept = meta_dict[\"concept\"]\n",
    "    print(\"Testing with concept:\", concept)\n",
    "    \n",
    "    reax_id = int(meta_dict[\"_id\"])\n",
    "    sae_id = int(meta_dict[\"sae_concept\"].split(\"/\")[-1])\n",
    "\n",
    "    # test prompt\n",
    "    reax_factory = ReAXFactory(\n",
    "        model, tokenizer,\n",
    "        concepts=[concept], \n",
    "        dump_dir=dump_dir)\n",
    "\n",
    "    positive_df = reax_factory.create_eval_df(n=val_n, category=\"positive\")\n",
    "    negative_df = reax_factory.create_eval_df(n=val_n, category=\"negative\")\n",
    "    hard_negative_df = reax_factory.create_eval_df(n=val_n, category=\"hard negative\")\n",
    "    \n",
    "    validation_df = pd.concat([positive_df, negative_df, hard_negative_df], axis=0)\n",
    "    all_sae_acts = []\n",
    "    all_reax_acts = []\n",
    "    all_sae_max_act = []\n",
    "    all_reax_max_act = []\n",
    "    for _, row in validation_df.iterrows():\n",
    "        inputs = tokenizer.encode(\n",
    "            row[\"input\"], return_tensors=\"pt\", add_special_tokens=True).to(\"cuda\")\n",
    "        # sae acts\n",
    "        sae_acts = pv_sae_model.forward(\n",
    "            {\"input_ids\": inputs}, return_dict=True\n",
    "        ).collected_activations[0][1:, sae_id].data.cpu().numpy().tolist() # no bos token\n",
    "        sae_acts = [round(x, n_decimal) for x in sae_acts]\n",
    "        max_sae_act = max(sae_acts)\n",
    "        \n",
    "        # reax acts\n",
    "        reax_in = gather_residual_activations(model, LAYER, inputs)\n",
    "        reax_acts, _ = reax_intervention.encode(\n",
    "            reax_in[:,1:], # no bos token\n",
    "            subspaces={\n",
    "                \"input_subspaces\": torch.tensor([reax_id])}, k=reax_topk)\n",
    "        reax_acts = reax_acts.flatten().data.cpu().numpy().tolist()\n",
    "        reax_acts = [round(x, n_decimal) for x in reax_acts]\n",
    "        max_reax_act = max(reax_acts)\n",
    "        \n",
    "        all_sae_acts += [sae_acts]\n",
    "        all_reax_acts += [reax_acts]\n",
    "        all_sae_max_act += [max_sae_act]\n",
    "        all_reax_max_act += [max_reax_act]\n",
    "        \n",
    "    validation_df['sae_acts'] = all_sae_acts\n",
    "    validation_df['reax_acts'] = all_reax_acts\n",
    "    validation_df['max_sae_act'] = all_sae_max_act\n",
    "    validation_df['max_reax_act'] = all_reax_max_act\n",
    "    validation_df['reax_id'] = reax_id\n",
    "    validation_df['sae_id'] = sae_id\n",
    "    all_validation_dfs += [validation_df]\n",
    "\n",
    "all_validation_df = pd.concat(all_validation_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a03b61b3-f972-439e-8231-14875332d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_validation_df.to_csv(\"./tmp/all_validation_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "544caa36-1c9c-4481-8de1-964183d8a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the HTML content with the dropdown for selecting REAX ID\n",
    "html_content_interactive = generate_html_with_concept(\n",
    "    pd.read_csv(\"./tmp/all_validation_df.csv\"), \n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "# Save the updated HTML content to a new file\n",
    "output_file_interactive = './tmp/highlighted_text.html'\n",
    "with open(output_file_interactive, 'w') as file:\n",
    "    file.write(html_content_interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f993956-1e61-4040-a54a-13ec73533197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
