{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5163c951-1173-44e3-9b7b-8bb760628c6a",
   "metadata": {},
   "source": [
    "## Basic *symbolic*-level control with SubCTRL.\n",
    "\n",
    "Create an intervention schema such that:\n",
    "\n",
    "**\"whenever the model reads in words related to Stanford, it will say something about human rights issues\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8dc40-dfc2-4d76-aa0c-e411ae783ee9",
   "metadata": {},
   "source": [
    "#### Set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4693b498-6e94-4a27-a3c2-c98f6631bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import subctrl\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    # relative import; better to pip install subctrl\n",
    "    import sys\n",
    "    sys.path.append(\"..\")\n",
    "    import subctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cdecf6-962c-4511-8e01-ca5fca892959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/wuzhengx/ipykernel_1542553/107260354.py:17: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, pyreft\n",
    "from pyvene import (\n",
    "    IntervenableModel,\n",
    "    ConstantSourceIntervention,\n",
    "    SourcelessIntervention,\n",
    "    TrainableIntervention,\n",
    "    DistributedRepresentationIntervention,\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from circuitsvis.tokens import colored_tokens\n",
    "from IPython.core.display import display, HTML\n",
    "from subctrl import EXAMPLE_TAG, SubCTRLFactory, MaxReLUIntervention, make_data_module\n",
    "from subctrl import (\n",
    "    set_decoder_norm_to_unit_norm, \n",
    "    remove_gradient_parallel_to_decoder_directions,\n",
    "    gather_residual_activations\n",
    ")\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11aead0-4475-48ba-8d7c-666ff3c87d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924bff8ca47f4555966d9220cda32e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088c5c6db0d54fb8a3526b0773379dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load lm.\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cpu\")\n",
    "model.config.use_cache = False\n",
    "model = model.cuda()\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fc614-5539-4568-b2d4-97abb1427219",
   "metadata": {},
   "source": [
    "#### SubCTRL dataset creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdd29567-2d69-4b0c-8f55-612473ebb8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prepare contrast concepts.\n",
      "Skipping contrast concept creation for references to institutional affiliations and events within the academic and legal contexts, particularly related to Stanford and Silicon Valley.\n",
      "Skipping contrast concept creation for references to human rights issues and related organizations.\n",
      "Creating dataframe.\n",
      "Fectching data for 0/2 concept: references to institutional affiliations and events within the academic and legal contexts, particularly related to Stanford and Silicon Valley\n",
      "Fectching data for 1/2 concept: references to human rights issues and related organizations\n",
      "Finished creating dataframe in 50.314 sec with $0.487.\n"
     ]
    }
   ],
   "source": [
    "subctrl_factory = SubCTRLFactory(\n",
    "    model, tokenizer,\n",
    "    concepts=[\n",
    "        # https://www.neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/16278\n",
    "        \"references to institutional affiliations and events within \"\\\n",
    "        \"the academic and legal contexts, particularly related to \"\\\n",
    "        \"Stanford and Silicon Valley\",   # subspace 1\n",
    "        # https://www.neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/11553\n",
    "        \"references to human rights issues and related organizations\", # subspace 2\n",
    "    ], \n",
    "    dump_dir=\"./tmp\",\n",
    "    skip_contrast_concept=True,\n",
    ")\n",
    "\n",
    "# dataset\n",
    "subctrl_df = subctrl_factory.create_df(n=48) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89a8a85-7d33-44e8-b293-06f87ec2616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_concept</th>\n",
       "      <th>output_concept</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>group</th>\n",
       "      <th>input_subspace</th>\n",
       "      <th>output_subspace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>The curious cat chased butterflies across the ...</td>\n",
       "      <td>. The cat was a black cat with a white spot on...</td>\n",
       "      <td>EXAMPLE_TAG.CONTROL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>references to human rights issues and related ...</td>\n",
       "      <td>references to institutional affiliations and e...</td>\n",
       "      <td>Yesterday the community organized a picnic Amn...</td>\n",
       "      <td>near Stanford's innovation hub involving lega...</td>\n",
       "      <td>EXAMPLE_TAG.EXPERIMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>references to institutional affiliations and e...</td>\n",
       "      <td>references to human rights issues and related ...</td>\n",
       "      <td>Tomorrow, we will attend the annual picnic Sta...</td>\n",
       "      <td>including Amnesty International's efforts and...</td>\n",
       "      <td>EXAMPLE_TAG.EXPERIMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       input_concept  \\\n",
       "0                                               null   \n",
       "1  references to human rights issues and related ...   \n",
       "2  references to institutional affiliations and e...   \n",
       "\n",
       "                                      output_concept  \\\n",
       "0                                               null   \n",
       "1  references to institutional affiliations and e...   \n",
       "2  references to human rights issues and related ...   \n",
       "\n",
       "                                               input  \\\n",
       "0  The curious cat chased butterflies across the ...   \n",
       "1  Yesterday the community organized a picnic Amn...   \n",
       "2  Tomorrow, we will attend the annual picnic Sta...   \n",
       "\n",
       "                                              output                   group  \\\n",
       "0  . The cat was a black cat with a white spot on...     EXAMPLE_TAG.CONTROL   \n",
       "1   near Stanford's innovation hub involving lega...  EXAMPLE_TAG.EXPERIMENT   \n",
       "2   including Amnesty International's efforts and...  EXAMPLE_TAG.EXPERIMENT   \n",
       "\n",
       "   input_subspace  output_subspace  \n",
       "0               0                1  \n",
       "1               1                0  \n",
       "2               0                1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subctrl_df.groupby(['input_concept', 'output_concept']).first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625ae7b-7cf9-47a0-a59d-f8f96d94646a",
   "metadata": {},
   "source": [
    "#### SubCTRL training.\n",
    "\n",
    "Let's focus on a single layer, layer 20 of the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23a8e0e6-95d2-4b0a-8ddc-422fef733a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable intervention params: 4,608 || trainable model params: 0\n",
      "model params: 2,614,341,888 || trainable%: 0.0001762585077778473\n"
     ]
    }
   ],
   "source": [
    "layer = 20\n",
    "\n",
    "# make data module.\n",
    "data_module = make_data_module(tokenizer, model, subctrl_df)\n",
    "train_dataloader = DataLoader(\n",
    "    data_module[\"train_dataset\"], shuffle=True, batch_size=8, \n",
    "    collate_fn=data_module[\"data_collator\"])\n",
    "\n",
    "# get reft model\n",
    "model = model.eval()\n",
    "subctrl_intervention = MaxReLUIntervention(\n",
    "    embed_dim=model.config.hidden_size, low_rank_dimension=1,\n",
    ")\n",
    "subctrl_intervention = subctrl_intervention.train()\n",
    "reft_config = pyreft.ReftConfig(representations=[{\n",
    "    \"layer\": l,\n",
    "    \"component\": f\"model.layers[{l}].output\",\n",
    "    \"low_rank_dimension\": 1,\n",
    "    \"intervention\": subctrl_intervention} for l in [layer]])\n",
    "reft_model = pyreft.get_reft_model(model, reft_config)\n",
    "reft_model.set_device(\"cuda\")\n",
    "reft_model.print_trainable_parameters()\n",
    "\n",
    "# optimizer and lr\n",
    "num_epochs = 9\n",
    "optimizer = torch.optim.AdamW(reft_model.parameters(), lr=5e-3)\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer,\n",
    "    num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e8d42c8-031e-478e-80c9-a73678f7d81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21942eb888247898ec9fc89f5eb2aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main training loop.\n",
    "progress_bar, curr_step = tqdm(range(num_training_steps)), 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        # prepare input\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "        unit_locations={\"sources->base\": (\n",
    "            None,\n",
    "            inputs[\"intervention_locations\"].permute(1, 0, 2).tolist()\n",
    "        )}\n",
    "        subspaces = [{\n",
    "            \"input_subspaces\": inputs[\"input_subspaces\"],\n",
    "            \"output_subspaces\": inputs[\"output_subspaces\"]}]\n",
    "\n",
    "        # forward\n",
    "        _, cf_outputs = reft_model(\n",
    "            base={\n",
    "                \"input_ids\": inputs[\"input_ids\"],\n",
    "                \"attention_mask\": inputs[\"attention_mask\"]\n",
    "            }, unit_locations=unit_locations, labels=inputs[\"labels\"],\n",
    "            subspaces=subspaces, use_cache=False)\n",
    "\n",
    "        # loss\n",
    "        loss = cf_outputs.loss\n",
    "        latent = reft_model.full_intervention_outputs[0].latent\n",
    "        null_loss = (latent.mean(dim=-1)*(inputs[\"groups\"]==EXAMPLE_TAG.CONTROL.value))\n",
    "        null_loss = null_loss.sum()\n",
    "        coeff = curr_step/num_training_steps\n",
    "        loss += coeff*0.1*null_loss\n",
    "        \n",
    "        # grads\n",
    "        loss.backward()\n",
    "        set_decoder_norm_to_unit_norm(subctrl_intervention)\n",
    "        remove_gradient_parallel_to_decoder_directions(subctrl_intervention)\n",
    "        curr_step += 1\n",
    "        curr_lr = get_lr(optimizer)\n",
    "        # optim\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\"lr %.6f || loss %.6f || null l1 loss %.6f\" % (curr_lr, loss, null_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe179309-30c9-41a3-8e38-faa94f7c0688",
   "metadata": {},
   "source": [
    "#### Symbolic-like steering with gated interventions on subspaces.\n",
    "\n",
    "We use one subspace to gate the steering with the second subspace. In other words:\n",
    "- We have one subspace acted as the steering wheel.\n",
    "- We have another who tells us how much to steer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d244f4c7-5e1a-44b2-8779-ceded3cf7ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09133310ddbb40d08d93dc9110ff6533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d394c34a3904936be892dc60f18accd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the chat-lm\n",
    "chat_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\", # google/gemma-2b-it\n",
    "    device_map='cpu',\n",
    ")\n",
    "chat_model.config.use_cache = False\n",
    "chat_model = chat_model.cuda()\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "_ = chat_model.eval()\n",
    "\n",
    "class SubspaceGatedAdditionIntervention(\n",
    "    SourcelessIntervention,\n",
    "    TrainableIntervention, \n",
    "    DistributedRepresentationIntervention\n",
    "):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Note that we initialise these to zeros because we're loading in pre-trained weights.\n",
    "        # If you want to train your own SAEs then we recommend using blah\n",
    "        super().__init__(**kwargs, keep_last_dim=True)\n",
    "        self.proj = torch.nn.Linear(\n",
    "                self.embed_dim, kwargs[\"low_rank_dimension\"]*2, bias=True)\n",
    "\n",
    "    def forward(self, base, source=None, subspaces=None):\n",
    "        bs, seql, _ = base.shape # b, s, d\n",
    "        base_r = base.reshape(bs*seql, -1).clone()\n",
    "        base_gate = torch.relu(base_r @ self.proj.weight[subspaces[\"gate\"]].unsqueeze(dim=-1)) # b*s, 1\n",
    "        steering_vec = torch.tensor(subspaces[\"mag\"]) * base_gate * self.proj.weight[subspaces[\"steer\"]]\n",
    "        base_s = base_r + steering_vec\n",
    "        output = base_s.reshape(bs, seql, -1)\n",
    "        if seql != 1:\n",
    "            # reset for the prompt tokens only.\n",
    "            output[:,0] = base[:,0]\n",
    "        return output\n",
    "\n",
    "gate_steering_intervention = SubspaceGatedAdditionIntervention(\n",
    "    embed_dim=model.config.hidden_size, low_rank_dimension=1,\n",
    ")\n",
    "gate_steering_intervention.cuda()\n",
    "gate_steering_intervention.proj.weight.data = subctrl_intervention.proj.weight.data\n",
    "\n",
    "reft_config = pyreft.ReftConfig(representations=[{\n",
    "    \"layer\": l,\n",
    "    \"component\": f\"model.layers[{l}].output\",\n",
    "    \"low_rank_dimension\": 1,\n",
    "    \"intervention\": gate_steering_intervention} for l in [20]])\n",
    "steering_model = pyreft.get_reft_model(chat_model, reft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a2b74-1f90-477a-92fc-7d4f45c93437",
   "metadata": {},
   "source": [
    "#### A simple test case\n",
    "\n",
    "**\"whenever the model reads in words related to Stanford, it will say something about human rights issues\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67f13464-b326-4843-9363-529390511e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mag = references to institutional affiliations and events within the academic and legal contexts, particularly related to Stanford and Silicon Valley\n",
      "+ 2.0 * mag * references to human rights issues and related organizations\n",
      "user\n",
      "List top 10 universities in the U.S. with a short reason.\n",
      "\n",
      "\n",
      "It's impossible to definitively say which are the \"top 10\" as rankings vary depending on factors like:\n",
      "\n",
      "* **Academic reputation:**  How well-regarded is the university for research and teaching?\n",
      "* **Faculty quality:** Are there renowned professors and experts in various fields?\n",
      "* **Resources and facilities:** Does the university have state-of-the-art labs, libraries, and technology?\n",
      "* **Student selectivity:** How competitive is the admissions process?\n",
      "* **Graduation rates and job placement:** What are the success rates of graduates?\n",
      "\n",
      "However, here are 10 consistently highly ranked US universities across different ranking systems, along with their strengths:\n",
      "\n",
      "**1. Massachusetts Institute of Technology (MIT):** Renowned for its focus on STEM fields, particularly engineering and computer science.\n",
      "**2. Stanford University:** Strong emphasis on human rights, global issues, and innovation.\n",
      "**3. Harvard University:** Prestigious institution known for its liberal arts education and impact on global affairs.\n",
      "**4. California Institute of Technology (Caltech):** Leading research university focused on science and engineering.\n",
      "**5. Princeton University:** Highly selective university with strong programs in humanities, social sciences, and natural sciences.\n",
      "**6. Columbia University:** Known for its global perspective, diverse student body, and commitment to public service.\n",
      "**7. University of Chicago:** Focuses on rigorous academic standards, critical thinking, and interdisciplinary studies.\n",
      "**8. University of Pennsylvania:** Excellent resources, strong alumni network, and prominent programs in law, business, and medicine.\n",
      "**9. Yale University:** Renowned for its history, intellectual legacy, and commitment to research and scholarship.\n",
      "**10. Northwestern University:** Strong programs in law, journalism, business, and international relations.\n",
      "\n",
      "\n",
      "Remember that this list is subjective and based on general consensus. The best university for you depends on your individual interests, goals, and preferences. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"List top 10 universities in the U.S. with a short reason.\"\n",
    "gate_concept_id = 0\n",
    "steer_concept_id = 1\n",
    "mag = 2.0\n",
    "print(f\"mag =\", subctrl_factory.concepts[gate_concept_id])\n",
    "print(f\"+ {mag} * mag *\", subctrl_factory.concepts[steer_concept_id])\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}]\n",
    "prompt = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", return_dict=True).to(\"cuda\")\n",
    "\n",
    "_, reft_response = steering_model.generate(\n",
    "    prompt, \n",
    "    unit_locations=None, \n",
    "    intervene_on_prompt=True, \n",
    "    subspaces=[{\"gate\": gate_concept_id, \"steer\": steer_concept_id, \"mag\": mag}], max_new_tokens=512, \n",
    "    do_sample=False, early_stopping=True, no_repeat_ngram_size=5, repetition_penalty=1.1\n",
    ")\n",
    "print(tokenizer.decode(reft_response[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c3b31-9996-4c27-b783-acca13b1d4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
