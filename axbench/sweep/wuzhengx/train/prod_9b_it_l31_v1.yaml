train:
  model_name: "google/gemma-2-9b-it"
  layer: 31
  component: "res"
  seed: 42
  use_bf16: true
  models:
    DiffMean:
      batch_size: 6
      n_epochs: 1
      binarize_dataset: true
      low_rank_dimension: 1
    SparseLinearProbe:
      batch_size: 6
      gradient_accumulation_steps: 1
      n_epochs: 12
      lr: 0.0005
      topk: 8
      coeff_latent_l1_loss: 0.005
      coeff_l1_loss: 0.00
      coeff_l2_loss: 0.02
      binarize_dataset: true
      low_rank_dimension: 1