generate:
  lm_model: "gpt-4o-mini"
  output_length: 64
  num_of_examples: 72
  concept_path: "axbench/data/gemma-2-9b-it_31-gemmascope-res-131k.json"
  max_concepts: 500 # 16000
  master_data_dir: "axbench/data"
  dataset_category: "instruction"
  lm_use_cache: false
  seed: 42
inference:
  model_name: "google/gemma-2-9b-it"
  output_length: 128
  latent_num_of_examples: 36
  master_data_dir: "axbench/data"
  seed: 42
  lm_model: "gpt-4o-mini"
