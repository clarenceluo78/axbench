# evaluate inference results
#    python benchmark/scripts/evaluate.py --config benchmark/sweep/evaluate/gemma-2-2b_20-gemmascope-res-16k.yaml --mode latent
latent_evaluators: ["AUCROCEvaluator"]
data_dir: "benchmark/results/gemma-2-2b_20-gemmascope-res-16k/inference"
dump_dir: "benchmark/results/gemma-2-2b_20-gemmascope-res-16k/"
rotation_freq: 1000