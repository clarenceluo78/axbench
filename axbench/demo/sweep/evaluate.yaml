models: [
  # "LinearProbe", "IntegratedGradients", "InputXGradients",
  # "L1LinearProbe", 
  "ReAX", "PromptSteering",
  # "GemmaScopeSAE", "MeanPositiveActivation",
  # "Random", "MeanEmbedding", "MeanActivation"
] 

latent_evaluators: [
  "AUCROCEvaluator",
  "HardNegativeEvaluator",
]
steering_evaluators: [
  "PerplexityEvaluator", 
  "LMJudgeConceptEvaluator",
  "LMJudgeFollowingEvaluator",
  # "LMJudgeContinuationEvaluator"
]
dump_dir: "axbench/demo"

# Number of processes to run in parallel for steering evaluation.
num_of_workers: 32
lm_model: "gpt-4o-mini"
run_winrate: true
winrate_baseline: "PromptSteering"

report_to: ["wandb"]
wandb_entity: "wuzhengx"