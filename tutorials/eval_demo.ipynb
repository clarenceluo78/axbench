{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9910b2c0-7fef-4544-ac75-7faa32140d59",
   "metadata": {},
   "source": [
    "## Evaluating ReAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf48181-f45b-4d37-9173-cb660e4925e5",
   "metadata": {},
   "source": [
    "#### Set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c79141-9bff-4d73-a9ff-fe411663fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import pyreax\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    # relative import; better to pip install subctrl\n",
    "    import sys\n",
    "    sys.path.append(\"../../pyreax\")\n",
    "    import pyreax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cfd8e8-e413-437a-90d5-7ce68560b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/wuzhengx/ipykernel_3820720/3683421786.py:19: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, pyreft\n",
    "from pathlib import Path\n",
    "from pyvene import (\n",
    "    IntervenableModel,\n",
    "    ConstantSourceIntervention,\n",
    "    SourcelessIntervention,\n",
    "    TrainableIntervention,\n",
    "    DistributedRepresentationIntervention,\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from circuitsvis.tokens import colored_tokens\n",
    "from IPython.core.display import display, HTML\n",
    "from pyreax import (\n",
    "    EXAMPLE_TAG, \n",
    "    ReAXFactory, \n",
    "    MaxReLUIntervention, \n",
    "    SubspaceAdditionIntervention, \n",
    "    JumpReLUSAECollectIntervention,\n",
    "    make_data_module, \n",
    "    save_reax,\n",
    "    load_reax,\n",
    "    load_sae,\n",
    "    generate_html_with_highlight_text\n",
    ")\n",
    "from pyreax import (\n",
    "    set_decoder_norm_to_unit_norm, \n",
    "    remove_gradient_parallel_to_decoder_directions,\n",
    "    gather_residual_activations,\n",
    "    get_lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb46e64e-b7ae-44dd-9c6a-10cde9ee47b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1702ae1f69544b878d79459d2405ea4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecdf5377f4840fb9d41bf1760ba6bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# params\n",
    "dump_dir = \"./tmp/gemma-2-2b/20-reax-res-gpt-4o/\"\n",
    "val_n = 10\n",
    "n_decimal = 3\n",
    "reax_topk = 10\n",
    "\n",
    "# Load saved meta.\n",
    "config, training_df, concept_metadata, weights = load_reax(dump_dir)\n",
    "\n",
    "# Load lm.\n",
    "model_name = config.model_name\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cpu\")\n",
    "model.config.use_cache = False\n",
    "model = model.cuda()\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "sae_weights = load_sae(concept_metadata)\n",
    "\n",
    "LAYER = config.layer\n",
    "\n",
    "reax_intervention = MaxReLUIntervention(\n",
    "    embed_dim=model.config.hidden_size, low_rank_dimension=weights.shape[0],\n",
    ")\n",
    "reax_intervention.proj.weight.data = weights.data\n",
    "_ = reax_intervention.cuda()\n",
    "pv_reax_model = IntervenableModel({\n",
    "   \"component\": f\"model.layers[{LAYER}].output\",\n",
    "   \"intervention\": reax_intervention}, model=model)\n",
    "\n",
    "sae_intervention = JumpReLUSAECollectIntervention(\n",
    "    embed_dim=sae_weights['W_enc'].shape[0],\n",
    "    low_rank_dimension=sae_weights['W_enc'].shape[1]\n",
    ")\n",
    "sae_intervention.load_state_dict(sae_weights, strict=False)\n",
    "_ = sae_intervention.cuda()\n",
    "pv_sae_model = IntervenableModel({\n",
    "   \"component\": f\"model.layers[{LAYER}].output\",\n",
    "   \"intervention\": sae_intervention}, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259325c-faf8-433e-882e-ea5e1a3cf12e",
   "metadata": {},
   "source": [
    "#### Latent activation eval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f93bf93-23af-455f-8844-98eae494db25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07:01:57:01,963 WARNING  [reax.py:171] Less than 2 concepts are provided. Only eval mode is allowed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with concept: terms related to artificiality and deception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07:01:57:02,340 WARNING  [reax.py:204] Prepare contrast concepts.\n",
      "2024-10-07:01:57:41,877 WARNING  [reax.py:215] Fectching 0 contrast concepts for concept: terms related to artificiality and deception\n",
      "2024-10-07:01:57:41,878 WARNING  [reax.py:220] Finished preparing contrast concepts in 39.537 sec with $0.03.\n",
      "2024-10-07:01:57:41,878 WARNING  [reax.py:225] Creating dataframe.\n",
      "2024-10-07:01:57:57,544 WARNING  [reax.py:225] Creating dataframe.\n",
      "2024-10-07:01:58:09,879 WARNING  [reax.py:225] Creating dataframe.\n",
      "2024-10-07:01:58:12,267 WARNING  [reax.py:171] Less than 2 concepts are provided. Only eval mode is allowed.\n",
      "2024-10-07:01:58:12,287 WARNING  [reax.py:204] Prepare contrast concepts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with concept: terms related to employment and employees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07:01:59:15,532 WARNING  [reax.py:215] Fectching 1 contrast concepts for concept: terms related to employment and employees\n",
      "2024-10-07:01:59:15,533 WARNING  [reax.py:220] Finished preparing contrast concepts in 63.245 sec with $0.056.\n",
      "2024-10-07:01:59:15,533 WARNING  [reax.py:225] Creating dataframe.\n",
      "2024-10-07:01:59:23,518 WARNING  [reax.py:225] Creating dataframe.\n",
      "2024-10-07:01:59:36,426 WARNING  [reax.py:225] Creating dataframe.\n"
     ]
    }
   ],
   "source": [
    "validation_df_map = {}\n",
    "id_sae_link_map = {}\n",
    "for meta in concept_metadata:\n",
    "    meta_dict = json.loads(meta)\n",
    "    concept = meta_dict[\"concept\"]\n",
    "    contrast_concepts = {}\n",
    "    contrast_concepts[concept] = meta_dict[\"contrast_concepts\"]\n",
    "    print(\"Testing with concept:\", concept)\n",
    "    \n",
    "    reax_id = int(meta_dict[\"_id\"])\n",
    "    sae_id = int(meta_dict[\"sae_concept\"].split(\"/\")[-1])\n",
    "    id_sae_link_map[reax_id] = meta_dict[\"sae_concept\"]\n",
    "    \n",
    "    # test prompt\n",
    "    reax_factory = ReAXFactory(\n",
    "        model, tokenizer,\n",
    "        concepts=[concept], \n",
    "        contrast_concepts=contrast_concepts,\n",
    "        dump_dir=dump_dir\n",
    "    )\n",
    "\n",
    "    positive_df = reax_factory.create_eval_df(n=val_n, category=\"positive\")\n",
    "    negative_df = reax_factory.create_eval_df(n=val_n, category=\"negative\")\n",
    "    hard_negative_df = reax_factory.create_eval_df(n=val_n, category=\"hard negative\")\n",
    "    validation_df = pd.concat([positive_df, negative_df, hard_negative_df], axis=0)\n",
    "    validation_df_map[concept] = validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a98ef75-9d60-4eca-8f19-d4193e9a635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with concept: terms related to artificiality and deception\n",
      "Testing with concept: terms related to employment and employees\n"
     ]
    }
   ],
   "source": [
    "all_validation_dfs = []\n",
    "for meta in concept_metadata:\n",
    "    meta_dict = json.loads(meta)\n",
    "    concept = meta_dict[\"concept\"]\n",
    "    contrast_concepts = {}\n",
    "    contrast_concepts[concept] = meta_dict[\"contrast_concepts\"]\n",
    "    print(\"Testing with concept:\", concept)\n",
    "    \n",
    "    reax_id = int(meta_dict[\"_id\"])\n",
    "    sae_id = int(meta_dict[\"sae_concept\"].split(\"/\")[-1]) \n",
    "    validation_df = validation_df_map[concept]\n",
    "    \n",
    "    all_sae_acts = []\n",
    "    all_reax_acts = []\n",
    "    all_sae_max_act = []\n",
    "    all_reax_max_act = []\n",
    "    for _, row in validation_df.iterrows():\n",
    "        inputs = tokenizer.encode(\n",
    "            row[\"input\"], return_tensors=\"pt\", add_special_tokens=True).to(\"cuda\")\n",
    "        # sae acts\n",
    "        sae_acts = pv_sae_model.forward(\n",
    "            {\"input_ids\": inputs}, return_dict=True\n",
    "        ).collected_activations[0][1:, sae_id].data.cpu().numpy().tolist() # no bos token\n",
    "        sae_acts = [round(x, n_decimal) for x in sae_acts]\n",
    "        max_sae_act = max(sae_acts)\n",
    "        \n",
    "        # reax acts\n",
    "        reax_in = gather_residual_activations(model, LAYER, inputs)\n",
    "        reax_acts, _ = reax_intervention.encode(\n",
    "            reax_in[:,1:], # no bos token\n",
    "            subspaces={\n",
    "                \"input_subspaces\": torch.tensor([reax_id])}, k=reax_topk)\n",
    "        reax_acts = reax_acts.flatten().data.cpu().numpy().tolist()\n",
    "        reax_acts = [round(x, n_decimal) for x in reax_acts]\n",
    "        max_reax_act = max(reax_acts)\n",
    "        \n",
    "        all_sae_acts += [sae_acts]\n",
    "        all_reax_acts += [reax_acts]\n",
    "        all_sae_max_act += [max_sae_act]\n",
    "        all_reax_max_act += [max_reax_act]\n",
    "        \n",
    "    validation_df['sae_acts'] = all_sae_acts\n",
    "    validation_df['reax_acts'] = all_reax_acts\n",
    "    validation_df['max_sae_act'] = all_sae_max_act\n",
    "    validation_df['max_reax_act'] = all_reax_max_act\n",
    "    validation_df['reax_id'] = reax_id\n",
    "    validation_df['sae_id'] = sae_id\n",
    "    validation_df['sae_link'] = meta_dict[\"sae_concept\"]\n",
    "    all_validation_dfs += [validation_df]\n",
    "\n",
    "all_validation_df = pd.concat(all_validation_dfs, axis=0)\n",
    "all_validation_df.to_csv(Path(dump_dir) / f\"val_latent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f993956-1e61-4040-a54a-13ec73533197",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content_interactive = generate_html_with_highlight_text(\n",
    "    id_sae_link_map,\n",
    "    pd.read_csv(Path(dump_dir) / f\"val_latent.csv\"), \n",
    "    tokenizer\n",
    ")\n",
    "output_file_interactive = Path(dump_dir) / f\"val_latent.html\"\n",
    "with open(output_file_interactive, 'w') as file:\n",
    "    file.write(html_content_interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90d7eb-4581-4f1b-aa2e-fcab90c28612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
